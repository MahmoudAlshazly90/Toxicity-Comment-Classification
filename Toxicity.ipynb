{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgcB6oDfD3SX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding\n",
        "from matplotlib import pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iIFOxs6Vp9vD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz_6GJH2im36",
        "outputId": "a7192fc4-ec7f-40b9-d34c-7e1be399a745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRlBmoimD3SZ",
        "outputId": "aba6b0d5-9679-4631-d898-f3dc034f95ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 id                                       comment_text  toxic  \\\n",
            "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
            "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
            "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
            "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
            "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
            "\n",
            "   severe_toxic  obscene  threat  insult  identity_hate  \n",
            "0             0        0       0       0              0  \n",
            "1             0        0       0       0              0  \n",
            "2             0        0       0       0              0  \n",
            "3             0        0       0       0              0  \n",
            "4             0        0       0       0              0  \n"
          ]
        }
      ],
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/Toxicity comments /train.csv\")\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsGlka7PD3SZ",
        "outputId": "1f7a625a-0384-423c-d1e7-1d604ddac6ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(159571, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['comment_text']\n",
        "y = df[df.columns[2:]].values\n"
      ],
      "metadata": {
        "id": "bsqU9xyqipDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_FEATURES = 200000 # number of words in the vocab\n"
      ],
      "metadata": {
        "id": "HfeK8GHAn_Pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TextVectorization(max_tokens=MAX_FEATURES,\n",
        "                               output_sequence_length=1800,\n",
        "                               output_mode='int')"
      ],
      "metadata": {
        "id": "cTgT537coOaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.adapt(X.values)\n",
        "vectorized_text = vectorizer(X.values)\n",
        "#MCSHBAP - map, chache, shuffle, batch, prefetch  from_tensor_slices, list_file\n",
        "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(160000)\n",
        "dataset = dataset.batch(16)\n",
        "dataset = dataset.prefetch(8) # helps bottlenecks\n",
        "#split dataset\n",
        "train = dataset.take(int(len(dataset)*.7))\n",
        "val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
        "test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
      ],
      "metadata": {
        "id": "C6ttGV2toRaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yFNzWkJbpp3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Model\n"
      ],
      "metadata": {
        "id": "bfpL3y9Gp-2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(MAX_FEATURES+1, 32))\n",
        "model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(6, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "LHSfp0cAqBqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='BinaryCrossentropy', optimizer='Adam')\n",
        "model.summary()\n",
        "history = model.fit(train, epochs=40, validation_data=val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqLxNRiTqEpG",
        "outputId": "fcc3037e-c67a-42ca-995f-e0d956ad74cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 32)          6400032   \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 64)                16640     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 6)                 774       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6491686 (24.76 MB)\n",
            "Trainable params: 6491686 (24.76 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "6981/6981 [==============================] - 825s 117ms/step - loss: 0.0613 - val_loss: 0.0434\n",
            "Epoch 2/40\n",
            "6981/6981 [==============================] - 714s 102ms/step - loss: 0.0457 - val_loss: 0.0419\n",
            "Epoch 3/40\n",
            "6981/6981 [==============================] - 712s 102ms/step - loss: 0.0407 - val_loss: 0.0371\n",
            "Epoch 4/40\n",
            "6981/6981 [==============================] - 698s 100ms/step - loss: 0.0364 - val_loss: 0.0313\n",
            "Epoch 5/40\n",
            "6981/6981 [==============================] - 697s 100ms/step - loss: 0.0331 - val_loss: 0.0296\n",
            "Epoch 6/40\n",
            "6981/6981 [==============================] - 701s 100ms/step - loss: 0.0294 - val_loss: 0.0257\n",
            "Epoch 7/40\n",
            "6981/6981 [==============================] - 697s 100ms/step - loss: 0.0264 - val_loss: 0.0241\n",
            "Epoch 8/40\n",
            "6981/6981 [==============================] - 712s 102ms/step - loss: 0.0244 - val_loss: 0.0219\n",
            "Epoch 9/40\n",
            "6981/6981 [==============================] - 722s 103ms/step - loss: 0.0219 - val_loss: 0.0187\n",
            "Epoch 10/40\n",
            "6981/6981 [==============================] - 710s 102ms/step - loss: 0.0201 - val_loss: 0.0180\n",
            "Epoch 11/40\n",
            "6981/6981 [==============================] - 717s 103ms/step - loss: 0.0183 - val_loss: 0.0161\n",
            "Epoch 12/40\n",
            "6981/6981 [==============================] - 736s 105ms/step - loss: 0.0164 - val_loss: 0.0145\n",
            "Epoch 13/40\n",
            "6981/6981 [==============================] - 717s 103ms/step - loss: 0.0154 - val_loss: 0.0121\n",
            "Epoch 14/40\n",
            "6981/6981 [==============================] - 712s 102ms/step - loss: 0.0134 - val_loss: 0.0108\n",
            "Epoch 15/40\n",
            "6981/6981 [==============================] - 711s 102ms/step - loss: 0.0125 - val_loss: 0.0108\n",
            "Epoch 16/40\n",
            "2428/6981 [=========>....................] - ETA: 6:51 - loss: 0.0106"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cx-n5HXsqbL_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j2bSRne0qPRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "draw graph"
      ],
      "metadata": {
        "id": "yC2GhPr-qP7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Uw6dIdV1qSUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make Predictions"
      ],
      "metadata": {
        "id": "1NGjL-mZqcLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = vectorizer('You freaking suck! I am going to hit you.')\n",
        "res = model.predict(input_text)\n"
      ],
      "metadata": {
        "id": "oGPBCoxaqdh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(res > 0.5).astype(int)\n",
        "batch_X, batch_y = test.as_numpy_iterator().next()\n"
      ],
      "metadata": {
        "id": "8D_9FvAQqkrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(model.predict(batch_X) > 0.5).astype(int)\n",
        "res.shape"
      ],
      "metadata": {
        "id": "nHg7UhWAqkzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy\n",
        "pre = Precision()\n",
        "re = Recall()\n",
        "acc = CategoricalAccuracy()\n",
        "for batch in test.as_numpy_iterator():\n",
        "    # Unpack the batch\n",
        "    X_true, y_true = batch\n",
        "    # Make a prediction\n",
        "    yhat = model.predict(X_true)\n",
        "\n",
        "    # Flatten the predictions\n",
        "    y_true = y_true.flatten()\n",
        "    yhat = yhat.flatten()\n",
        "\n",
        "    pre.update_state(y_true, yhat)\n",
        "    re.update_state(y_true, yhat)\n",
        "    acc.update_state(y_true, yhat)\n",
        "print(f'Precision: {pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')"
      ],
      "metadata": {
        "id": "Sot-dkjcEMKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('toxicity.h5')\n"
      ],
      "metadata": {
        "id": "NrgLV85uERSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('toxicity.h5')\n",
        "input_str = vectorizer('hey i freaken hate you!')\n",
        "res = model.predict(np.expand_dims(input_str,0))"
      ],
      "metadata": {
        "id": "K0-Oc7XbNg-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score_comment(comment):\n",
        "    vectorized_comment = vectorizer([comment])\n",
        "    results = model.predict(vectorized_comment)\n",
        "\n",
        "    text = ''\n",
        "    for idx, col in enumerate(df.columns[2:]):\n",
        "        text += '{}: {}\\n'.format(col, results[0][idx]>0.5)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "Q1ph9GnGNj0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interface = gr.Interface(fn=score_comment,\n",
        "                         inputs=gr.inputs.Textbox(lines=2, placeholder='Comment to score'),\n",
        "                        outputs='text')\n",
        "interface.launch(share=True)"
      ],
      "metadata": {
        "id": "VgJophrJNofi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ch0-Ol5bNpAI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}